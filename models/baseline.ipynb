{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dicom\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  Gets 3d data from DICOM file as (depth, width, height)\n",
    "'''\n",
    "def get_3d_data(path):\n",
    "  slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "  slices.sort(key=lambda x: int(x.InstanceNumber))\n",
    "  return np.stack([s.pixel_array for s in slices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  Makes one CT scan as a batch of 'image's with shape (224,224,3)\n",
    "  \n",
    "'''\n",
    "def make_batch(data_3d):\n",
    "  data_3d[data_3d == -2000] = 0\n",
    "\n",
    "  batch = []\n",
    "  for i in range(0, data_3d.shape[0] - 2):\n",
    "    tmp = []\n",
    "    for j in range(3):\n",
    "      img = data_3d[i + j]\n",
    "      img = 255.0 / np.amax(img) * img\n",
    "      img = cv2.equalizeHist(img.astype(np.uint8))\n",
    "      img = cv2.resize(img, (224, 224))\n",
    "      tmp.append(img)\n",
    "\n",
    "    # transpose 3,224,224 to 224,224,3 for the vgg16 feed dict.\n",
    "    tmp = np.transpose(tmp, (1, 2, 0))\n",
    "    batch.append(np.array(tmp))\n",
    "\n",
    "  batch = np.array(batch)\n",
    "  return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  Gets the graph definition from the pre-trained vgg16-model.\n",
    "  \n",
    "'''\n",
    "def get_graph_def():\n",
    "  with open(\"vgg16.tfmodel\", mode='rb') as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "  graph_def = tf.GraphDef()\n",
    "  graph_def.ParseFromString(fileContent)\n",
    "\n",
    "  return graph_def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  Extracts features from the CT scans and save them locally.\n",
    "\n",
    "'''\n",
    "def extract_features(data):\n",
    "  graph_def = get_graph_def()\n",
    "  print('graph loaded from disk')\n",
    "\n",
    "  images = tf.placeholder(\"float\", [None, 224, 224, 3])\n",
    "  tf.import_graph_def(graph_def, input_map={\"images\": images})\n",
    "\n",
    "  graph = tf.get_default_graph()\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "\n",
    "    #####################\n",
    "    # TODO: should be in a loop\n",
    "    data = get_3d_data('../data/sample/images/0a0c32c9e08cc2ea76a71649de56be6d')\n",
    "    batch = make_batch(data)\n",
    "    feed_dict = {images: batch}\n",
    "\n",
    "    fc_tensor = graph.get_tensor_by_name(\"import/fc8:0\")\n",
    "    feats = sess.run(fc_tensor, feed_dict=feed_dict)\n",
    "    # TODO: save the feats, do we need average or other operations to have a \n",
    "    # smaller feature vector over the batch?\n",
    "\n",
    "  return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  Trains the model with extracted feature.\n",
    "\n",
    "'''\n",
    "def train(data):\n",
    "  extractor = get_extractor()\n",
    "\n",
    "  # feats = get_features(extractor, data)\n",
    "\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  Makes prediction with the model trained.\n",
    "  \n",
    "'''\n",
    "def predict(model, x):\n",
    "  return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "#   data = get_3d_data('../data/sample/images/0a0c32c9e08cc2ea76a71649de56be6d')\n",
    "#   batch = make_batch(data)\n",
    "#   print(batch.shape)\n",
    "  \n",
    "   # model = train(train_data)\n",
    "   # preds = predict(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}